# RVNN Rumour- original readme below.
CHANGELOG:
* Attempted to add a preprocess creator.
* Keep in mind that Ma's Code is meant for 4 classes, but appears able to function with less (possibly with some edits)
* you will need to download PHEME here - https://figshare.com/articles/dataset/PHEME_dataset_for_Rumour_Detection_and_Veracity_Classification/6392078


- readme u2b tag removed.
- added new pointers.
- added a counter for the trees, located in resource fabrication. Place with raw twitter 15/16 dataset folder to count the trees in preprocessed VS actual trees in dataset.

* \1 = ['news', 'non-rumor']
* \2 = ['false']
* \3 = ['true']
* \4 = ['unverified']

* Reprocess 15/16 according as similarly to Ma's preprocess as possible. 
* You will be missing some tweet texts. The tweet will not be added to the final output file if this is the case.
1  run get_all_unknowntweets.py, or just use the pulled_tweets.zip i placed. It's whatever tweets i could pull that are not deleted, or privated.
2 skip this step if you didn't run  get_all_unknowntweets.py.  Run pull_relevants.py, which is a general twitter pulling code. it should automatically reference unseen_tweet_list which is a list of unseen tweets that is generated by the step before. It should auto continue from where you left off if you stop halfway.
3 run preprocess_T15_T16.py which will generate the relevant files which you can then place into the resource folder.


# PHEME

1  Extract from PHEME file: "all-rnr-annotated-threads"
2  run pheme_to_rvnn_converter.py -> converts it into a similar format as the original twitter 15/16 dataset (with one additional file)
3  it will create: 
	>transposed_label.txt 
	>transposed_source_tweets.txt
	>fake_tree  a directory containing fake trees similar to how twitter15/16 organise their data.
4  run preprocess_PHEME.py. it will produce the files you need to place into the resource folder and the nfold folder.












# Paper of the source codes released:

Jing Ma, Wei Gao, Kam-Fai Wong. Rumor Detection on Twitter with Tree-structured Recursive Neural Networks. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018.

# Datasets:

The datasets used in the experiments were based on the two publicly available Twitter datasets released by Ma et al. (2017):

Jing Ma, Wei Gao, Kam-Fai Wong. Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning. ACL 2017.

In the 'resource' folder we provide the pre-processed data files used for our experiments. The raw datasets can be downloaded from https://www.dropbox.com/s/7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0. For details about the datasets please contact Jing at: majing at se dot cuhk dot edu dot hk.

The datafile is in a tab-sepreted column format, where each row corresponds to a tweet. Consecutive columns correspond to the following pieces of information:

1: root-id -- an unique identifier describing the tree (tweetid of the root);

2: index-of-parent-tweet -- an index number of the parent tweet for the current tweet;

3: index-of-the-current-tweet -- an index number of the current tweet;

4: parent-number -- the total number of the parent node in the tree that the current tweet is belong to;

5: text-length -- the maximum length of all the texts from the tree that the current tweet is belong to;

6: list-of-index-and-counts -- the rest of the line contains space separated index-count pairs, where a index-count pair is in format of "index:count", E.g., "index1:count1 index2:count2" (extracted from the "text" field in the json format from Twitter)


# Dependencies:
Please install the following python libraries:

numpy version 1.11.2

theano version 0.8.2

# Reproduce the experimental results
Run script "model/Main_BU_RvNN.py" for bottom-up recursive model or "model/Main_TD_RvNN.py" for up-down recursive model.

Alternatively, you can change the "obj" parameter and "fold" parameter to set the dataset and each fold.

#If you find this code useful, please let us know and cite our paper.
